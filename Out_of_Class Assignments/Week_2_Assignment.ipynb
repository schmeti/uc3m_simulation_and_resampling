{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Week 2\n",
    "\n",
    "Simulation and Resampling\n",
    "\n",
    "- MARCOS ÁLVAREZ MARTÍN\n",
    "- SIMON SCHMETZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "\n",
    "# get first 50 rows\n",
    "iris_setosa_df = iris_df.iloc[:50]\n",
    "\n",
    "iris_setosa_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapiro-Wilk Normality Test\n",
    "\n",
    "First, we perform the Shapiro-Wilk normality test to verify the normality of the data with\n",
    "\n",
    "$H_0:$ Data is normaly distributed\n",
    "\n",
    "$H_1:$ Data is not normaly distributed\n",
    "\n",
    "With the following resulting P-Values. We se that with significane 5%, for all features except for the petal width, the null hypothesis is not rejected. The petal length P-Value however is however not as high as it is for sepal width and length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# perform iris_setosa_df test\n",
    "\n",
    "print(\"P-Values of Shapiro Wilk normality test\")\n",
    "for column in iris_setosa_df.columns:\n",
    "    stat, p_value = stats.shapiro(iris_setosa_df[column])\n",
    "    print(f\"{column}: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Validate the findings, histograms together with fitted normal distributions show how well the data fits or does not fit a normal distribution. The Strong rejection of normality for petal width is confirmed by the corresponding histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set up fig\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# plot each column\n",
    "for i, column in enumerate(iris_setosa_df.columns):\n",
    "    data = iris_setosa_df[column]\n",
    "    \n",
    "    # plot hist\n",
    "    axs[i].hist(data, bins=10, density=True, alpha=0.6, color='g')\n",
    "    \n",
    "    # Plot normal distribution fitted to the data\n",
    "    mu, std = norm.fit(data)\n",
    "    xmin, xmax = axs[i].get_xlim()\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    p = norm.pdf(x, mu, std)\n",
    "    axs[i].plot(x, p, 'k', linewidth=2)\n",
    "    \n",
    "    # cosmetics\n",
    "    axs[i].set_title(f'Histogram and Normal Distribution of {column}')\n",
    "    axs[i].set_xlabel(column)\n",
    "    axs[i].set_ylabel('Density')\n",
    "\n",
    "# plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kolmogorov-Smirnov Test\n",
    "\n",
    "Alternatively, the Kolmogorov-Smirnov Test can be used to perform a similar evaluation of nomrality. As Kolmogorov-Smirnov is a nonparametric test, we need to give a reference distribution which in our case is the normal distribution with parameters mean and variance taken as the sample mean and the sample variance. \n",
    "\n",
    "The test gives a similar result as the Shapiro-Wilk test, with a general slight increase in P-Values for all Features. The conclusions drawn previously however remain the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Kolmogorov-Smirnov test\n",
    "print(\"P-Values of Kolmogorov-Smirnov test with normal distribution as reference\")\n",
    "\n",
    "teststat_values_iris = {}\n",
    "\n",
    "\n",
    "for column in iris_setosa_df.columns:\n",
    "    # fit normal distribution & perform test\n",
    "    mu, std = norm.fit(iris_setosa_df[column])\n",
    "    ks_statistic, ks_p_value = stats.kstest(iris_setosa_df[column], 'norm', args=(mu, std))\n",
    "\n",
    "    # store test staitic value\n",
    "    teststat_values_iris[column] = ks_statistic\n",
    "\n",
    "    # print\n",
    "    print(f\"{column}: {ks_p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation\n",
    "\n",
    "For a sample size of 50, we perform 1000 Monte Carlo Simulations by drawing random samples from a normal distribution, estimating the parameters of a normal distribution on each of those samples and performing a Kolmogorov-Smirnov with a normal distribution defined by the estimated parameters als reference. The test results (test statistic value and p-Value) are stored. For further analysis, the P-Values are plotted as histograms, showing how the majority of Tests have P-Values close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Vars\n",
    "M = 1000  # Number of simulations\n",
    "n = 50  # Number of observations\n",
    "\n",
    "ks_statistics = []\n",
    "p_values = []\n",
    "\n",
    "\n",
    "# Simulation\n",
    "for _ in range(M):\n",
    "    # Generate sample and estimate params\n",
    "    sample = np.random.normal(loc=0, scale=1, size=n)\n",
    "    mu, std = norm.fit(sample)\n",
    "    \n",
    "    # Perform test\n",
    "    ks_statistic, p_value = stats.kstest(sample, 'norm', args=(mu, std))\n",
    "    \n",
    "    # store test values\n",
    "    ks_statistics.append(ks_statistic)\n",
    "    p_values.append(p_value)\n",
    "\n",
    "# plot p-Values\n",
    "plt.hist(p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximates the p-value of the normality Kolmogorov-Smirnov test\n",
    "\n",
    "By comparing the P-Values from the real dataset with the P-Values from simulated samples, we can approximate the P-Value of the normality Kolmogorov-Smirnov test, e.g. the probability that a even greater test statistic could come from a random sample of a normal distribution. The resulting \"P-Values\" for sepal length and width as well as for petal width are in line with previous evaluation of normality. Meanwhile, petal length has contrary to previous findings a lower P-Value impying non-normality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "percentages = {}\n",
    "for column, test_stat in teststat_values_iris.items():\n",
    "    count = sum(1 for stat in ks_statistics if stat > test_stat)\n",
    "    percentage = (count / len(ks_statistics))\n",
    "    percentages[column] = percentage\n",
    "\n",
    "percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The findings can be validated by plotting the distirbution of the test statistic for the simulation and the test statistic values calculated for the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make histogram\n",
    "plt.hist(ks_statistics, bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "colors = ['red', 'green', 'orange', 'purple']\n",
    "\n",
    "for i, column in enumerate(iris_setosa_df.columns):\n",
    "    plt.axvline(teststat_values_iris[column], color=colors[i], linestyle='dashed', linewidth=2, label=f'Test statistic {column}')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('KS Statistic')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 3 - Building Confidence Interval\n",
    "\n",
    "In the following Excercise, calculate the required number of observations to build a 99% CI on $\\int_{0}^{1} \\exp(e^x) \\, dx$ with a width of 0.05 Units. We do so by first simulating 1000 observations drawn from a Uniform and estimating the standard deviation of $\\exp(e^x)$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "M = 1000\n",
    "\n",
    "# draw sample and calculate std\n",
    "U = np.random.uniform(0, 1, M)\n",
    "exp_U = np.exp(U)\n",
    "std_exp_U = np.std(exp_U, ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the the dependence between CI length ($l_{CI}$) and number of observations ($n$) \n",
    "$$2*\\pm \\text{z} \\cdot \\frac{\\sigma_U}{\\sqrt{n}}=l_{CI}$$\n",
    "$$ n = \\left( \\frac{2 \\cdot \\text{z} \\cdot \\sigma_U}{l_{CI}} \\right)^2$$\n",
    "to calculate the required number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate params\n",
    "z_score = stats.norm.ppf(0.995) \n",
    "desired_width = 0.05\n",
    "\n",
    "# calculate required n\n",
    "required_n = (2 * z_score * std_exp_U / desired_width)^2\n",
    "\n",
    "print(f\"Number of observations needed: {int(np.ceil(required_n))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
